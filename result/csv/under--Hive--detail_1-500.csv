search_string,predict_under_code,line_no,similarity,filepath
"//  FIXME: probably this should also be integrated with isSame() logics","private static boolean areMergeable(ParseContext pctx, SharedWorkOptimizerCache optimizerCache,",655,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java
"//  Wait for t1 to block, just be sure. Not ideal...","State s;",575,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/tez/TestWorkloadManager.java
"// HIVE-17328: not sure this is correct... I don't think is gets wrapped in UDFToInteger....","bucketColumns.add(new ExprNodeColumnDesc(ci));",209,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SortedDynPartitionOptimizer.java
"//  We expect this to never happen in practice. Can pool paths even have angled braces?","} while (result != null);",940,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java
"//  TODO: This does not work correctly. None of the partitions is created, but the folder   for the first two is created. It is because in HiveMetaStore.add_partitions_core when   going through the partitions, the first two are already put and started in the thread   pool when the exception occurs in the third one. When the exception occurs, we go to   the finally part, but the map can be empty (it depends on the progress of the other   threads) so the folders won't be deleted.      Assert.assertFalse(metaStore.isPathExists(new Path(tableLocation + "/year=2016")));","too long.",0,0,0
"//  TODO: remove this after stashing only rqd pieces from opconverter","private final SemanticAnalyzer                              semanticAnalyzer;",122,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveOpConverter.java
"//  TODO: should we try to make a giant array for one cache call to avoid overhead?","for (Map.Entry<Long, Long> missingChunk : chunksInThisRead.entrySet()) {",267,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/llap/LlapCacheAwareFs.java
"//  Forward the row to reducer as is.   Discard the row.   Vectorized - may forward the row, not sure yet.","None",None,None,None
"//  7. Handle any move session requests. The way move session works right now is   a) sessions get moved to destination pool if there is capacity in destination pool   b) if there is no capacity in destination pool, the session gets killed (since we cannot pause a query)   TODO: in future this the process of killing can be delayed until the point where a session is actually required.   We could consider delaying the move (when destination capacity is full) until there is claim in src pool.   May be change command to support ... DELAYED MOVE TO etl ... which will run under src cluster fraction as long","too long.",0,0,0
"//  Not thread-safe.","System.out.println("Getting versions from " + queryDir);",2177,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"// it would be better if AlreadyExistsException had an errorCode field....","throw new HiveException(ex, ErrorMsg.DATABSAE_ALREADY_EXISTS, crtDb.getName());",4831,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  TODO: this can probably be replaced with much less code via dynamic dispatch and/or templates.","private PreInsertTableDesc preInsertTableDesc;",36,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
"//  TODO Handle this properly","throw new RuntimeException("ContainerInfo not found for container: " + containerId +",376,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
"//  TODO: Do we need maxLength checking?","byte[] bytes = hiveVarchar.getValue().getBytes();",786,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAssignRow.java
"//  TODO: prewarm and update can probably be merged.","update();",512,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
"//  @deprecated in favour of {@link HCatTable.#getTblProps()}. To be removed in Hive 0.16.","public Map<String, String> getTblProps() {",199,0.9333333333333333,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: disabling this test as tez publishes counters only after task completion which will cause write side counters   to be not validated correctly (DAG will be completed before validation)    @Test(timeout = 60000)","public void testTriggerSlowQueryExecutionTime() throws Exception {",45,0.19900497512437812,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestTriggersNoTezSessionPool.java
"//  TODO: might want to increase the default batch size. 1024 is viable; MS gets OOM if too high.","int nParts = partNames.size();",3090,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
"//  TODO: remove when averageTypeValueSize method RelMdSize","//       supports all types",120,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/HiveRelMdSize.java
"//  We store all caches in variables to change the main one based on config.   This is not thread safe between different split generations (and wasn't anyway).","private FooterCache footerCache;",608,0.6387434554973822,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  $x/$user/appcache/$appId/${dagId}/output/$mapId   TODO: Once Shuffle is out of NM, this can use MR APIs to convert   between App and Job","String parts[] = jobIdString.split("_");",1074,0.593939393939394,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/ShuffleHandler.java
"// todo: does this need the finalDestination?","desc = new FileSinkDesc(basePath, tableDesc, false, 1, false,",287,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFileSinkOperator.java
"//  todo: add LIMIT 1 instead of count - should be more efficient","s = "select count(*) from COMPLETED_TXN_COMPONENTS where CTC_TXNID = " + txnid;",4235,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
"/*      * TODO: client.executeStatement do not support listing resources command     * (beeline> list jar)      */","// Assert.assertEquals("expected uri", api.getAddedResource("jar"));",145,0.8533333333333334,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/test/org/apache/hive/service/cli/session/TestSessionGlobalInitFile.java
"//  Note: scheduler will call this based on lack of sources at schedule time and set this         to true... there's no easy way to work around this. Need better classes","if (this.canUpdateFinishable) {",363,0.7093596059113301,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/test/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorTestHelpers.java
"//  TODO: will this also fix windowing? try","RowResolver inputRR = this.relToHiveRR.get(srcRel), starRR = inputRR;",4344,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"//  but let's make it a little bit more explicit.","if (allPartitions != null) {",3939,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  TODO: This should inherit from VolcanoCost and should just override isLE   method.","public class HiveCost implements RelOptCost {",31,0.9481481481481482,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/cost/HiveCost.java
"//  TODO: 1) check for duplicates 2) We assume in clause values to be   present in NDV which may not be correct (Range check can find it) 3) We   assume values in NDV set is uniformly distributed over col values   (account for skewness - histogram).","selectivity = computeFunctionSelectivity(call) * (call.operands.size() - 1);",117,0.43478260869565216,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java
"//  TODO: if we didn't care about the column order, we could switch join sides here","//       for TOK_JOIN and TOK_FULLOUTERJOIN.",9546,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  TODO: we could remember if it's unsupported and stop sending calls; although, it might         be a bad idea for HS2+standalone metastore that could be updated with support.         Maybe we should just remember this for some time.","if (!resp.isIsSupported()) {",2605,0.5836575875486382,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClientPreCatalog.java
"//  @deprecated in favour of {@link HCatTable.#location(String)}. To be removed in Hive 0.16.","public Builder location(String location) {",310,0.935672514619883,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: why is this like that?","for(ReadEntity re : partitionsRead) {",1012,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/UpdateDeleteSemanticAnalyzer.java
"/*  TODO Escape handling may be changed by a follow on.     * The largest issue is ; which are treated as statement     * terminators for the cli. Once the cli is fixed this     * code should be re-investigated      */","while (command.charAt(startPosition++) != '`' && startPosition < command.length()){",154,0.42718446601941745,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/processors/CompileProcessor.java
"//  Delete data?   Fail if table doesn't exist?   Need results back?","None",None,None,None
"//  TODO: This does not work correctly. None of the partitions is created, but the folder   for the first two is created. It is because in HiveMetaStore.add_partitions_core when   going through the partitions, the first two are already put and started in the thread   pool when the exception occurs in the third one.   When the exception occurs, we go to the finally part, but the map can be empty   (it depends on the progress of the other threads) so the folders won't be deleted.   Assert.assertTrue(metaStore.isPathExists(new Path(partition1.getSd().getLocation())));   Assert.assertTrue(metaStore.isPathExists(new Path(partition2.getSd().getLocation())));   Assert.assertTrue(metaStore.isPathExists(new Path(partition3.getSd().getLocation())));","too long.",0,0,0
"//  Note: we assume that this isn't an already malformed query;         we don't check for that here - it will fail later anyway.","// First, we find the SELECT closest to the top.",402,0.6933333333333334,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
"//  TODO - not clear if we should cache these or not.  For now, don't bother","@Override",2202,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
"//  TODO: this needs to be removed; see TestReplicationScenarios* comments.","HIVE_IN_TEST_REPL("hive.in.repl.test", false, "internal usage only, true in replication test mode", true),",582,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
"// BUG: This will not work in remote mode - HIVE-5153","String currDb = SessionState.get().getCurrentDatabase();",892,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java
"//  TODO Change this method to make the output easier to parse (parse programmatically)","Set<String> result = new LinkedHashSet<>();",231,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java
"//  TODO: remove?","RowIndex[] getRowIndexes();",32,0.3684210526315789,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/ConsumerStripeMetadata.java
"//  Wouldn't it make more sense to return the first element of the list returned by the   previous call?","return new Partition();",3917,0.9150326797385621,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
"//  a better logic would be to find the alias","theMRInput = (MRInputLegacy) inp.getValue();",518,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
"//  we need to enforce the size here even the types are the same","return valuesReader.readBytes().getBytesUnsafe();",106,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/vector/ParquetDataColumnReaderFactory.java
"//  This method may not be safe as it can throw an NPE if a key or value is null.","return Maps.fromProperties(properties);",725,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HCatUtil.java
"//  TODO: this is an ugly hack because Tez plugin isolation does not make sense for LLAP plugins.         We are going to register a thread-local here for now, so that the scheduler, initializing         in the same thread after the communicator, will pick up. Or the other way around.","too long.",0,0,0
"//  TODO MS-SPLIT uncomment once we move EventMessage over","@Test",520,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/TestObjectStore.java
"//  Follow hive's rules for type inference as oppose to Calcite's   for return type.  TODO: Perhaps we should do this for all functions, not just +,-","case "-":",565,0.6206896551724138,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
"//  TODO: [HIVE-6289] while getting stats from metastore, we currently only get one col at         a time; this could be improved - get all necessary columns in advance, then use local.   TODO: [HIVE-6292] aggregations could be done directly in metastore. Hive over MySQL!","too long.",0,0,0
"//  TODO: see planIndexReading; this is not needed here.","private static boolean hadBadBloomFilters(TypeDescription.Category category,",2099,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"//  TODO: why is it stored in both table and dpCtx?","int numBuckets = (conf.getTable() != null) ? conf.getTable().getNumBuckets()",1382,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
"//  TODO: Use threadpool for more concurrency?   TODO: check/set all files, or only directories","checkAndSetFileOwnerPermissions(fs, subFile, userName, groupName, dirPerms, filePerms, dryRun, recurse);",893,0.6610169491525424,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/util/HiveStrictManagedMigration.java
"//  TODO HIVE-15865 Handle additional reasons like OS launch failed","sb.append("\tFAILED container: ");",516,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapStatusServiceDriver.java
"//  TODO: 1) handle Agg Func Name translation 2) is it correct to add func","// args as child of func?",230,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java
"//  TODO: Both of these are TException, why do we need these separate clauses?","if (e instanceof MetaException) {",5953,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
"//  TODO: if two HS2s start at exactly the same time, which could happen during a coordinated         restart, they could start generating the same IDs. Should we store the startTime","//       somewhere like ZK? Try to randomize it a bit for now...",91,0.6909090909090909,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/coordinator/LlapCoordinator.java
"//  TODO: given the specific data and lookups, perhaps the nested thing should not be a map         In fact, CSLM has slow single-threaded operation, and one file is probably often read         by just one (or few) threads, so a much more simple DS with locking might be better.         Let's use CSLM for now, since it's available.","too long.",0,0,0
"//  TODO Ideally this should be done independent of whether mr is setup or not.","setFsRelatedProperties(conf, fs.getScheme().equals("file"),fs);",381,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  This is not modeled as a @Before, because it needs to be parameterized per-test.   If there is a better way to do this, we should do it.","private void initHS2(boolean enableXSRFFilter) throws Exception {",64,0.770949720670391,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestXSRFFilter.java
"//  todo HIVE-5269","return new String((byte[])obj);",178,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java
"//  Make sure null-valued ConfVar properties do not override the Hadoop Configuration   NOTE: Comment out the following test case for now until a better way to test is found,   as this test case cannot be reliably tested. The reason for this is that Hive does   overwrite fs.default.name in HiveConf if the property is set in system properties.   checkHadoopConf(ConfVars.HADOOPFS.varname, "core-site.xml");   checkConfVar(ConfVars.HADOOPFS, null);   checkHiveConf(ConfVars.HADOOPFS.varname, "core-site.xml");","too long.",0,0,0
"//  @deprecated in favour of {@link HCatPartition.#getDatabaseName()}. To be removed in Hive 0.16.","public String getDatabaseName() {",101,0.9392265193370166,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatAddPartitionDesc.java
"// TODO: due to value 101 this probably should throw an exception","List<String> partitionNames = client.listPartitionNames(DB_NAME, TABLE_NAME,",1124,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java
"//  @deprecated in favour of {@link HCatTable.#getSortCols()}. To be removed in Hive 0.16.","public List<Order> getSortCols() {",189,0.9333333333333333,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  Hmm.. not good,   the only type expected here is STRUCT, which maps to HCatRecord   - anything else is an error. Return null as the inspector.","throw new SerDeException("TypeInfo [" + typeInfo.getTypeName()",74,0.22900763358778625,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/HCatRecordObjectInspectorFactory.java
"//  TODO: should these rather be arrays?","private Map<Integer, String> parentToInput = new HashMap<Integer, String>();",62,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/MapJoinDesc.java
"//  TODO Change all this to be based on a regular interface instead of relying on the Proto service - Exception signatures cannot be controlled without this for the moment.","public class LlapProtocolClientImpl implements LlapProtocolBlockingPB {",46,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-common/src/java/org/apache/hadoop/hive/llap/impl/LlapProtocolClientImpl.java
"//  PolicyChangeListener will be implemented later","}",137,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hive/service/server/TestInformationSchemaWithPrivilege.java
"//  TODO: do we actually need this reader? the caller just extracts child readers.","return StructStreamReader.builder()",2266,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedTreeReaderFactory.java
"//  TODO HIVE-14042. What is mergeWork, and why is it not part of the regular operator chain.   The mergeMapOp.initialize call further down can block, and will not receive information   about an abort request.","MapWork mergeMapWork = (MapWork) mergeWork;",215,0.6129032258064516,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
"//  TODO HIVE-15163. Handle cases where nodes go down and come back on the same port. Historic information","// can prevent updates from being sent out to the new node.",566,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
"//  TODO: most protocol exceptions are probably unrecoverable... throw?","caughtException = (TException)t;",234,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/RetryingMetaStoreClient.java
"//  TODO: do we also need to remove the MapJoin from the list of RS's children?","}",454,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezWork.java
"//  TODO: why is there a TezSession in MR ExecDriver?","if (ss != null && HiveConf.getVar(job, ConfVars.HIVE_EXECUTION_ENGINE).equals("tez")) {",410,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
"//  Replace INSERT OVERWRITE by MERGE equivalent rewriting.   Here we need to do this complex AST rewriting that generates the same plan   that a MERGE clause would generate because CBO does not support MERGE yet.   TODO: Support MERGE as first class member in CBO to simplify this logic.","too long.",0,0,0
"//  TODO: Current implementation of replication will result in DROP_PARTITION under replication   scope being called per-partition instead of multiple partitions. However, to be robust, we   must still handle the case of multiple partitions in case this assumption changes in the   future. However, if this assumption changes, we will not be very performant if we fetch   each partition one-by-one, and then decide on inspection whether or not this is a candidate   for dropping. Thus, we need a way to push this filter (replicationSpec.allowEventReplacementInto)   to the  metastore to allow it to do drop a partition or not, depending on a Predicate on the   parameter key values.","too long.",0,0,0
"//  TODO: should we pass curr instead of null?","curr = genPostGroupByBodyPlan(groupByOperatorInfo, dest, qb, aliasToOpInfo, null);",6238,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  Really not sure if this should go here.  Will have   to see how the storage mechanism evolves.","if (type.equals(Type.JOB)) {",125,0.7058823529411765,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperStorage.java
"//  TODO Force fs to file://, setup staging dir?        conf.set("fs.defaultFS", "file:///");        conf.set(TezConfiguration.TEZ_AM_STAGING_DIR, "/tmp");","conf.setBoolean("tez.runtime.optimize.local.fetch", true);",864,0.43902439024390244,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/TestAcidOnTez.java
"// todo: why not just use getRootDir()?","assert root.equals(orcSplit.getRootDir()) : "root mismatch: baseDir=" + orcSplit.getRootDir() +",357,0.66,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/VectorizedOrcAcidRowBatchReader.java
"//  TODO: lossy conversion!","}",529,0.5542168674698795,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/udf/ptf/ValueBoundaryScanner.java
"//  TODO: remove the copy after ORC-158 and ORC-197","// if (bb.isDirect()) {",546,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
"//  TODO: If the DB name doesn't match with the metadata from dump, then need to rewrite the original and expanded   texts using new DB name. Currently it refers to the source database name.","this.createViewDesc.setViewOriginalText(originalText);",142,0.7530364372469636,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/ImportTableDesc.java
"//  TODO: remove this constructor","}",41,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/TableSchema.java
"//  TODO: add the ability to extractFileTail to read from multiple buffers?","MemoryBuffer[] tailBufferArray = tailBuffers.getMultipleBuffers();",554,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
"//  TODO : instead of simply restricting by message format, we should eventually   move to a jdbc-driver-stype registering of message format, and picking message   factory per event to decode. For now, however, since all messages have the   same factory, restricting by message format is effectively a guard against   older leftover data that would cause us problems.","too long.",0,0,0
"//  TODO: When hive moves to java8, make updateTimezone() as default method in","// SettableTreeReader so that we can avoid this check.",321,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/decode/OrcEncodedDataConsumer.java
"//  Not strictly necessary, noone will look at it.","if (newCacheData == null) {",304,0.7321428571428571,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/llap/LlapCacheAwareFs.java
"//  2**exponent part is scaling down while 10**scale is scaling up.   Now it's tricky.   unscaledValue = significand * 10**scale / 2**twoScaleDown","short twoScaleDown = (short) -exponent;",393,0.632768361581921,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hadoop/hive/common/type/Decimal128.java
"//  TODO CAT - I am fairly certain that most calls to this are in error.  This should only be   used when the database location is unset, which should never happen except when a   new database is being created.  Once I have confirmation of this change calls of this to   getDatabasePath(), since it does the right thing.  Also, merge this with   determineDatabasePath() as it duplicates much of the logic.","too long.",0,0,0
"//  TODO: Should this be the concern of the mutator?","deleteDeltaIfExists(newPartitionPath, table.getWriteId(), newBucketId);",233,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/worker/MutatorCoordinator.java
"//  TODO: Provide support for reporting errors   This should never happen as server always returns a valid status on success","throw new RuntimeException("SubmissionState in response is expected!");",429,0.5531914893617021,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskCommunicator.java
"/*  TODO: ideally, when the splits UDF is made a proper API, coordinator should not   *        be managed as a global. HS2 should create it and then pass it around.  */","private static final LlapCoordinator INSTANCE = new LlapCoordinator();",155,0.6344086021505376,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/coordinator/LlapCoordinator.java
"//  TODO: convert sqlState, etc.","TStatus tStatus = new TStatus(TStatusCode.ERROR_STATUS);",119,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/HiveSQLException.java
"//  TODO Include EXTERNAL_PREEMPTION in this list?","// TODO HIVE-16134. Differentiate between EXTERNAL_PREEMPTION_WAITQUEU vs EXTERNAL_PREEMPTION_FINISHABLE?",1211,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  To workaround AvroUTF8","// This also gets us around the Enum issue since we just take the value",256,0.6567164179104478,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java
"//  TODO needs to go in InitializeInput? as part of InputJobInfo","private static HCatSchema getOutputSchema(Configuration conf)",67,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatBaseInputFormat.java
"//  Note that this logic may drop some of the tables of the database   even if the drop database fail for any reason   TODO: Fix this","List<String> materializedViews = getTables(dbName, ".*", TableType.MATERIALIZED_VIEW);",1032,0.6878980891719745,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
"//  Some walkers extending DefaultGraphWalker e.g. ForwardWalker   do not use opQueue and rely uniquely in the toWalk structure,   thus we store the results produced by the dispatcher here   TODO: rewriting the logic of those walkers to use opQueue","too long.",0,0,0
"//  This is a corner case where we have an extract of time unit like day/month pushed as Extraction Fn  @TODO The best way to fix this is to add explicit output Druid types to Calcite Extraction Functions impls","output.add(new IntWritable(Integer.valueOf((String) value)));",442,0.6507936507936508,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/druid-handler/src/java/org/apache/hadoop/hive/druid/serde/DruidSerDe.java
"//  Workaround for HADOOP-12659 - remove when Hadoop 2.7.X is no longer supported.","private void checkForZKDTSMBug() {",90,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-common/src/java/org/apache/hadoop/hive/llap/security/SecretManager.java
"//  We could pass in the number of nodes that we expect instead of -1.   Also, a single concurrent request per node is currently hardcoded.","super(LlapProtocolClientProxy.class.getSimpleName(), numThreads, conf, llapToken,",49,0.6586826347305389,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/tez/LlapProtocolClientProxy.java
"//  TODO: Strangely the default parametrization is to ignore missing tables","client.dropTable("no_such_database", table.getTableName());",555,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestTablesCreateDropAlterTruncate.java
"//  FIXME : should clean up TEST_PATH, but not doing it now, for debugging's sake","}",185,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenarios.java
"//  This will throw error if we close pout early.","streams.out.close();",82,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-common/src/test/org/apache/hadoop/hive/llap/io/TestChunkedInputStream.java
"//  It is not a very clean way, and should be modified later - due to   compatibility reasons,   user sees the results as json for custom scripts and has no way for   specifying that.   Right now, it is hard-coded in the code","if (useDelimitedJSON) {",268,0.4649122807017544,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
"//  TODO This test passes fine locally but fails on Linux, not sure why","public void createCatalogWithBadLocation() throws TException {",184,0.9421487603305785,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestCatalogs.java
"//  TODO: SeekableInputStream.readFully eventually calls a Hadoop method that used to be         buggy in 2.7 and also anyway just does a copy for a direct buffer. Do a copy here.   ((SeekableInputStream)stream).readFully(bb);","FileUtils.readFully(stream, length, bb);",245,0.5823754789272031,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/metadata/MetadataCache.java
"//  TODO: 1) Expand to other functions as needed 2) What about types other than primitive.","TypeInfo tgtDT = null;",246,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
"//  Set footer cache for current split generation. See field comment - not thread safe.","// TODO: we should be able to enable caches separately",701,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  TODO: the below seem like they should just be combined into partitionDesc","private org.apache.hadoop.hive.ql.plan.TableDesc table;",45,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java
"//  CallableWithNdc inherits from NDC only when call() is invoked. CallableWithNdc has to   extended to provide access to its ndcStack that is cloned during creation. Until, then   we will use reflection to access the private field.   FIXME: HIVE-14243 follow to remove this reflection","too long.",0,0,0
"//  TODO: this is brittle. Who said everyone has to upgrade using upgrade process?","assert isSplitUpdate : "should be true in Hive 3.0";",252,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcSplit.java
"/*    * Check whether a task can run to completion or may end up blocking on it's sources.   * This currently happens via looking up source state.   * TODO: Eventually, this should lookup the Hive Processor to figure out whether   * it's reached a state where it can finish - especially in cases of failures   * after data has been fetched.   *   * @return true if the task can finish, false otherwise    */","too long.",0,0,0
"//  UNDONE: How to look for all NULLs in a multi-key?????  Let nulls through for now.","public VectorMapJoinOptimizedMultiKeyHashMap(boolean isOuterJoin,",30,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/mapjoin/optimized/VectorMapJoinOptimizedMultiKeyHashMap.java
"//  Note: this can still conflict with parallel transactions. We do not currently handle         parallel changes from two admins (by design :().","copyName = generateOldPlanName(newName, ++i);",11251,0.783068783068783,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO: time good enough for now - we'll likely improve this.   We may also work in something the equivalent of pid, thrid and move to nanos to ensure   uniqueness.","private void dumpFunctionMetadata(String dbName, Path dumpRoot) throws Exception {",387,0.5573770491803278,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
"//  FIXME: somehow place pointers that re-execution compilation have failed; the query have been successfully compiled before?","return compile_resp;",173,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecDriver.java
"//  UNDONE: Haven't finished isRepeated","assert !isRepeated;",374,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/util/batchgen/VectorColumnGroupGenerator.java
"//  hack, instead figure out a way to get the db paths","String isExternal = table.getParameters().get("EXTERNAL");",161,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveMetaStoreChecker.java
"// TODO: support complex types   for complex type we simply return 0","return 0;",1376,0.6419753086419753,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUtils.java
"//  TODO: the control flow for this needs to be defined. Hive is supposed to be thread-local.","private Hive sessionHive;",117,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
"// todo: should be at the top of the file...","pw.println(",455,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/upgrade-acid/src/main/java/org/apache/hadoop/hive/upgrade/acid/UpgradeTool.java
"//  Get rid of TOK_SELEXPR","expr = (ASTNode) child.getChild(0);",4507,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  Clear the work map after build. TODO: remove caching instead?","Utilities.clearWorkMap(conf);",488,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezTask.java
"//  DO_NOT_UPDATE_STATS is supposed to be a transient parameter that is only passed via RPC   We want to avoid this property from being persistent.     NOTE: If this property *is* set as table property we will remove it which is incorrect but   we can't distinguish between these two cases     This problem was introduced by HIVE-10228. A better approach would be to pass the property","too long.",0,0,0
"//  This is using the payload from the RootVertexInitializer corresponding   to InputName. Ideally it should be using it's own configuration class -   but that","// means serializing another instance.",170,0.6564102564102564,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/CustomPartitionVertex.java
"//  like HiveHBaseTableInputFormat cannot be used with this (todo)","private static class FetchInputFormatSplit extends HiveInputFormat.HiveInputSplit {",760,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/FetchOperator.java
"//  @deprecated in favour of {@link HCatTable.#collectionItemsTerminatedBy()}. To be removed in Hive 0.16.","public Builder collectionItemsTerminatedBy(char delimiter) {",393,0.9441624365482234,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: Once HBASE-11163 is completed, use that API, or switch to   using mapreduce version of the APIs. rather than mapred   Copied from HBase's TableMapreduceUtil since it is not public API","static String convertScanToString(Scan scan) throws IOException {",52,0.5164319248826291,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableSnapshotInputFormat.java
"//  TODO: Fetch partitions in batches?   TODO: Threadpool to process partitions?","for (String partName : partNames) {",501,0.6464646464646465,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/util/HiveStrictManagedMigration.java
"//  TODO : simple wrap & rethrow for now, clean up with error codes","LOG.warn("Error during analyzeReplDump", e);",228,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/ReplicationSemanticAnalyzer.java
"// todo: add method to only get current i.e. skip history - more efficient","ShowCompactResponse currentCompactions = txnHandler.showCompact(new ShowCompactRequest());",91,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/Initiator.java
"/*  * Simple wrapper of object with ObjectInspector. *  * TODO: we need to redefine the hashCode and equals methods, so that it can be * put into a HashMap as a key. *  * This class also serves as a facility for a function that returns both an * object and an ObjectInspector.  */","too long.",0,0,0
"//  The ordering of types here is used to determine which numeric types   are common/convertible to one another. Probably better to rely on the   ordering explicitly defined here than to assume that the enum values   that were arbitrarily assigned in PrimitiveCategory work for our purposes.","too long.",0,0,0
"//  Something else is wrong","e.printStackTrace();",181,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/svr/src/test/java/org/apache/hive/hcatalog/templeton/tool/TestTempletonUtils.java
"//  TODO: Comments in RexShuttle.visitCall() mention other   types in this category. Need to resolve those together   and preferably in the base class RexShuttle.","newCall =",2157,0.5483870967741935,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRelDecorrelator.java
"//  TODO: Verify if this is needed (Why can't it be always null/empty","String tabAlias = addEmptyTabAlias ? "" : null;",1233,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveGBOpConvUtil.java
"//  is the outer join that we saw most recently is a right outer join?","boolean lastSeenRightOuterJoin = false;",511,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
"//  TODO: this relies on HDFS not changing the format; we assume if we could get inode ID, this         is still going to work. Otherwise, file IDs can be turned off. Later, we should use         as public utility method in HDFS to obtain the inode-based path.","private static final String HDFS_ID_PATH_PREFIX = "/.reserved/.inodes/";",60,0.5547445255474452,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/utils/HdfsUtils.java
"//  TODO: should it rather do a prefix?","if (lbDirSuffix.startsWith(Path.SEPARATOR)) {",2059,0.543859649122807,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
"/*    * TODO This method is temporary. Ideally Hive should only need to pass to Tez the amount of memory   *      it requires to do the map join, and Tez should take care of figuring out how much to allocate   * Adjust the percentage of memory to be reserved for the processor from Tez   * based on the actual requested memory by the Map Join, i.e. HIVECONVERTJOINNOCONDITIONALTASKTHRESHOLD   * @return the adjusted percentage    */","too long.",0,0,0
"//  A hack to verify that authorization check passed. Exception can be thrown be cause   the functions are not being called with valid params.   verify that exception has come from ObjectStore code, which means that the","// authorization checks passed.",89,0.568,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/AbstractTestAuthorizationApiAuthorizer.java
"//  TODO: should this use getUserFromAuthenticator?","hookContext = new PrivateHookContext(plan, queryState, ctx.getPathToCS(), SessionState.get().getUserName(),",2270,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
"// TODO: Move this to calcite","public class HiveRelMdPredicates implements MetadataHandler<BuiltInMetadata.Predicates> {",78,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/HiveRelMdPredicates.java
"//  TODO: add this to metadatareader in ORC - SI => metadata buffer, not just metadata.","if (LOG.isTraceEnabled()) {",668,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
"//  TODO: This should come from type system; Currently there is no definition","// in type system for this.",24,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveTypeSystemImpl.java
"//  TODO At the moment there's no way of knowing whether a query is running or not.   A race is possible between dagComplete and registerFragment - where the registerFragment   is processed after a dagCompletes.   May need to keep track of completed dags for a certain time duration to avoid this.   Alternately - send in an explicit dag start message before any other message is processed.   Multiple threads communicating from a single AM gets in the way of this.","too long.",0,0,0
"/*     Should we allow writing to non-transactional tables in an explicit transaction?  The user may    issue ROLLBACK but these tables won't rollback.    Can do this by checking ReadEntity/WriteEntity to determine whether it's reading/writing    any non acid and raise an appropriate error    * Driver.acidSinks and Driver.transactionalInQuery can be used if any acid is in the query */","too long.",0,0,0
"//  TODO: implement?","}",1553,0.3238095238095238,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"// todo: what is this checking????","return (files.size() > otherFiles.size())",950,0.651685393258427,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  I think this is wrong, the drop table statement should come on the table topic not the   DB topic - Alan.","String topicName = getTopicPrefix(tableEvent.getIHMSHandler().getConf()) + "." + table.getDbName().toLowerCase();",283,0.9171974522292994,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java
"//  TODO: rather, Tez sessions should not depend on SessionState.","private SessionState parentSessionState;",86,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionPool.java
"//  todo: support tez/vectorization","boolean useNontaged = conf.getBoolVar(",149,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LocalMapJoinProcFactory.java
"//  TODO: read this somewhere useful, like the task scheduler","srv.set(kv.getKey(), kv.getValue());",138,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java
"//  TODO Add support for serialization of values here","return null;",78,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hbase-handler/src/java/org/apache/hadoop/hive/hbase/struct/DefaultHBaseValueFactory.java
"//  TODO: Convert genIncludedColumns and setSearchArgument to use TypeDescription.","final List<OrcProto.Type> schemaTypes = OrcUtils.getOrcTypes(schema);",2152,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  TODO: when this code is a little less hot, change most logs to debug.   We will determine what to do under lock and then do stuff outside of the lock.   The approach is state-based. We consider the task to have a duck when we have decided to   give it one; the sends below merely fix the discrepancy with the actual state. We may add the   ability to wait for LLAPs to positively ack the revokes in future.   The "procedural" approach requires that we track the ducks traveling on network,   concurrent terminations, etc. So, while more precise it's much more complex.","too long.",0,0,0
"//  TODO: why doesn't this use context?","return new DoubleStreamReader(columnIndex, present, data, isFileCompressed, vectors);",1027,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedTreeReaderFactory.java
"//  Note: this is redundant with types","this.version = version;",160,0.6966292134831461,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"//  The following 2 lines are exactly what MySQL does TODO: why do we do this?","case '%':",563,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
"//  temporary variable for testing. This is added just to turn off this feature in case of a bug in   deployment. It has not been documented in hive-default.xml intentionally, this should be removed","// once the feature is stable",2844,0.6528925619834711,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
"//  TODO need session handle","TGetResultSetMetadataResp  metadataResp;",251,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java
"//  This is kind of hacky - the read entity contains the old table, whereas   the write entity   contains the new table. This is needed for rename - both the old and the   new table names are   passed","// Don't acquire locks for any of these, we have already asked for them in DDLSemanticAnalyzer.",3977,0.5607476635514018,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  UNDONE: For now, don't add more small keys...","/*",130,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/mapjoin/MapJoinTestData.java
"//  TODO: can this ever happen?","LOG.warn("Session configuration is null for " + wmTezSession);",1579,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
"//  TODO: there's a potential problem here if some table uses external schema like Avro,         with a very large type name. It seems like the view does not derive the SerDe from         the table, so it won't be able to just get the type from the deserializer like the         table does; we won't be able to properly store the type in the RDBMS metastore.","too long.",0,0,0
"//  TODO: this should depends on input format and be in a map, or something.","this.orcCvp = new OrcColumnVectorProducer(",198,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapIoImpl.java
"//  TODO: we can actually consider storing ALL the delta encoded row offsets - not a lot of         overhead compared to the data itself, and with row offsets, we could use columnar         blocks for inconsistent splits. We are not optimizing for inconsistent splits for now.","too long.",0,0,0
"//  TODO: should this just use physical IDs?","for (int i = 0; i < includes.getReaderLogicalColumnIds().size(); ++i) {",294,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapRecordReader.java
"//  TODO: wtf?!! why is this in this method? This has nothing to do with anything.","HashPartition hashPartition = new HashPartition(1024, (float) 0.75, 524288, 1, true, null);",27,0.2857142857142857,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/persistence/TestHashPartition.java
"//  This class isn't used and I suspect does totally the wrong thing.  It's only here so that I   can provide some output format to the tables and partitions I create.  I actually write to","// those tables directory.",508,0.6696428571428571,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/CompactorTest.java
"//  TODO: does arg need type cast?","aggArgRelDTBldr.add(TypeConverter.convert(expr.getTypeInfo(), dtFactory));",3373,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"// what??!!","return false;",398,0.5714285714285714,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/Warehouse.java
"//  TODO not sure this is the right exception","LOG.debug("Unable to stat file as current user, trying as table owner");",175,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorThread.java
"//  we need to convert the Hive type to the SQL type name   TODO: this would be better handled in an enum","if ("string".equalsIgnoreCase(type)) {",181,0.704,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/jdbc/src/java/org/apache/hive/jdbc/JdbcColumn.java
"//  TODO: NPE should not be thrown","client.add_partitions_pspec(null);",176,0.9818181818181818,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestAddPartitionsFromPartSpec.java
"//  CONSIDER: Allocate a larger initial size.","if(tempDecimalBuffer == null || tempDecimalBuffer.length < length) {",444,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/fast/BinarySortableDeserializeRead.java
"//  No good way to find out (may even have no app).","}",283,0.8764044943820225,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java
"//  Hardcode SASL here. ZKDTSM only supports none or sasl and we never want none.","zkConf.set(ZK_DTSM_ZK_AUTH_TYPE, "sasl");",185,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-common/src/java/org/apache/hadoop/hive/llap/security/SecretManager.java
"//  We support List<Object>, Set<Object> and Object[]   so we have to do differently.","if (! (data instanceof List)) {",62,0.7931034482758621,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/StandardListObjectInspector.java
"//  If wh is still null after just having initialized it, bail out - something's very wrong.","throw new IllegalStateException("Unable to initialize Warehouse from clientside.");",91,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
"//  TODO Convert this to an Assert.fail once HIVE-14682 is fixed","}",1150,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  TODO: we should be able to enable caches separately","footerCache = useExternalCache ? metaCache : localCache;",702,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  For dynamic partitioned hash join, the big table will also be coming from a ReduceSinkOperator   Check for this condition.   TODO: use indexOf(), or parentRS.getTag()?","isBigTable =",98,0.7321428571428571,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ReduceSinkMapJoinProc.java
"//  TODO:   Following HiveSubQueryFinder has been copied from RexUtil::SubQueryFinder   since there is BUG in there (CALCITE-1726).   Once CALCITE-1726 is fixed we should get rid of the following code","None",None,None,None
"//  TODO: Extend rule so it can be applied for these cases.","final Set<Operator<?>> workOps1 = findWorkOperators(optimizerCache, op1);",1130,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java
"//  TODO: Support case DATE:","break;",280,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnStatsAutoGatherContext.java
"//  TODO figure out a better way to set repeat for Binary type","c.isRepeating = false;",317,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/vector/VectorizedPrimitiveColumnReader.java
"//  TODO: If we are ok with breaking compatibility of existing 3rd party StorageHandlers,   this method could be moved to the HiveStorageHandler interface.","boolean retval = true;",5361,0.7317073170731707,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  TODO: This global lock may not be necessary as all concurrent methods in ICacheableMetaStoreClient   are synchronized.","synchronized (CACHE_TEARDOWN_LOCK) {",167,0.9157894736842105,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java
"// todo: FileSystem#setPermission() - should this make sure to set 777 on jobs/ ?","Path keyfile= new Path(getPath(type) + "/" + id + "/" + key);",70,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java
"/*  * Builder for relational expressions. * TODO: *  Note that this is copied from Calcite's RelBulder *  because CALCITE-1493 hasn't been fixed yet *  This should be deleted and replaced with RelBuilder in SubqueryRemoveRule *  once CALCITE-1493 is fixed. *  EDIT: Although CALCITE-1493 has been fixed and released but HIVE now has special handling *    in join (it gets a flag to see if semi join is to be created or not). So we still can not *    replace this with Calcite's RelBuilder * * <p>{@code RelBuilder} does not make possible anything that you could not * also accomplish by calling the factory methods of the particular relational * expression. But it makes common tasks more straightforward and concise. * * <p>{@code RelBuilder} uses factories to create relational expressions. * By default, it uses the default factories, which create logical relational * expressions ({@link org.apache.calcite.rel.logical.LogicalFilter}, * {@link org.apache.calcite.rel.logical.LogicalProject} and so forth). * But you could override those factories so that, say, {@code filter} creates * instead a {@code HiveFilter}. * * <p>It is not thread-safe.  */","too long.",0,0,0
"//  TODO: Setting autocommit should not generate an exception as long as it is set to false   beeLine.autocommitStatus(getConnection());","} catch (Exception e) {",170,0.7789473684210526,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/beeline/src/java/org/apache/hive/beeline/DatabaseConnection.java
"//  TODO: precision and scale would be practically invalid for string conversion (38,38)","int scale = HiveDecimalUtils.getScaleForType(ptinfo);",1048,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorizationContext.java
"//  TODO: Should this really default to FETCH_NEXT?","return FETCH_NEXT;",47,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/FetchOrientation.java
"//  TODO: Not sure about the use of this. Should we instead use workerIdentity as sessionId?","this.metrics = LlapTaskSchedulerMetrics.create(displayName, sessionId);",386,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  @deprecated in favour of {@link HCatTable.#tableType(HCatTable.Type)}. To be removed in Hive 0.16.","public Builder isTableExternal(boolean isExternal) {",334,0.9417989417989417,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: trace ranges here? Between data cache and incomplete cb cache","}",901,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
"//  FIXME: retain old error; or create a new one?","return cpr;",180,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/reexec/ReExecDriver.java
"//  we don't remove the work from the sparkWork here. The removal is done later.","private void moveWork(SparkWork sparkWork, BaseWork work, SparkWork targetWork) {",116,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/SparkMapJoinResolver.java
"//  TODO: need to move from Python to Java for the rest of the script.","JSONObject configs = createConfigJson(containerSize, cache, xmx, java_home);",567,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapServiceDriver.java
"//  check if input pruning is possible   TODO: this code is buggy - it relies on having one file per bucket; no MM support (by design).","boolean isManagedTable = part.getTable().getTableType() == TableType.MANAGED_TABLE;",194,0.4492753623188406,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SamplePruner.java
"//  todo: strictly speaking you can commit an empty txn, thus 2nd conjunct is wrong but   only   possible for for multi-stmt txns","boolean alreadyCommitted = rs2.next() && rs2.getInt(1) > 0;",4238,0.8160919540229885,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
"//  View DDL   "alter view add partition" does not work because of the nature of implementation   of the DDL in hive. Hive will internally invoke another Driver on the select statement,   and HCat does not let "select" statement through. I cannot find a way to get around it   without modifying hive code. So just leave it unsupported.","too long.",0,0,0
"// todo: to test these need to link against 3.x libs - maven profiles?  runStatementOnDriver("create table TFlat (a int, b int) stored as orc tblproperties('transactional'='false')");  runStatementOnDriver("create table TFlatText (a int, b int) stored as textfile tblproperties('transactional'='false')");","too long.",0,0,0
"//  NOTE : This is hacky, and this section of code is fragile depending on DN code varnames   so it's likely to stop working at some time in the future, especially if we upgrade DN   versions, so we actively need to find a better way to make sure the leak doesn't happen   instead of just clearing out the cache after every call.","too long.",0,0,0
"//  TODO: should never happen?","assert info.lastSetGuaranteed == null;",1289,0.5617977528089888,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  UNDONE: Don't know why HIVE-12894 causes this to return 0?   assertEquals(0.33, reader.getProgress(), 0.01);",""there should be " + String.valueOf(expectedNumOCleanedFiles) + " deleted files in cm root",",197,0.23853211009174313,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/txn/compactor/TestCleanerWithReplication.java
"//  @deprecated in favour of {@link HCatTable.#getLocation()}. To be removed in Hive 0.16.","public String getLocation() {",167,0.9333333333333333,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  we do not support Windows, we will revisit this if we really need it for windows.","return false;",208,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hadoop/hive/common/log/InPlaceUpdate.java
"//  Pass an empty list as no columns will be written to the file.   TODO I should be able to make this work for update","tableCols = new ArrayList<>();",404,0.7183098591549296,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java
"//  TODO: throw an exception?","}",1521,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java
"//  TODO: move to DynamicSerDe when it's ready","private Deserializer inputKeyDeserializer;",75,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecReducer.java
"//  TODO: Replace with direct call to ProgressHelper, when reliably available.","private static class ReflectiveProgressHelper {",76,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezProcessor.java
"//  TODO: this is the only place that uses keepTmpDir. Why?","TezSessionPoolManager.closeIfNotDefault(ss.getTezSession(), true);",412,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java
"//  TODO: use serdeConstants.COLLECTION_DELIM when the typo is fixed","collSep = LazyUtils.getByte(tbl.getProperty(COLLECTION_DELIM),",106,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/contrib/src/java/org/apache/hadoop/hive/contrib/serde2/MultiDelimitSerDe.java
"//  Indicates whether a node had a recent communication failure.   This is primarily for tracking and logging purposes for the moment.   TODO At some point, treat task rejection and communication failures differently.","private boolean hadCommFailure = false;",2426,0.4595744680851064,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  TODO: move other protocols to use this too.","public class ProtobufProxy<BlockingInterface> {",31,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-common/src/java/org/apache/hadoop/hive/llap/impl/ProtobufProxy.java
"//  TODO Move the following 2 properties out of Configuration to a constant.","LLAP_DAEMON_CONTAINER_ID("hive.llap.daemon.container.id", null,",3980,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
"/*  * Creates size estimators for java objects. The estimators attempt to do most of the reflection * work at initialization time, and also take some shortcuts, to minimize the amount of work done * during the actual estimation. * TODO: clean up  */","too long.",0,0,0
"//  TODO: move to a base class?","@Override",261,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
"//  Since the MapJoin has had all of its other parents removed at this point,   it would be bad here if processReduceSinkToHashJoin() tries to do anything","// with the RS parent based on its position in the list of parents.",447,0.6595744680851063,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezWork.java
"// todo: should this be done for MM?  is it ok to use CombineHiveInputFormat with MM","checkAcidConstraints(qb, table_desc, dest_tab);",7307,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  todo this should be changed to be evaluated lazily, especially for single segment case","keys[current].setFirst(JoinUtil.computeKeys(nextRow.o, keyFields, keyFieldOIs));",829,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/SMBMapJoinOperator.java
"//  TODO Disable blacklisting in Tez when using LLAP, until this is properly supported.   Blacklisting can cause containers to move to a terminating state, which can cause attempt to be marked as failed.   This becomes problematic when we set #allowedFailures to 0   TODO HIVE-13484 What happens when we try scheduling a task on a node that Tez at this point thinks is blacklisted.","too long.",0,0,0
"// todo should this check be in conformToAcid()?","LOG.info("Could not make " + Warehouse.getQualifiedName(newTable) + " acid: it's " +",266,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/TransactionalValidationListener.java
"//  TODO: Split count is not same as no of buckets","JoinAlgorithm oldAlgo = join.getJoinAlgorithm();",646,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/cost/HiveOnTezCostModel.java
"// TODO: Cols that come through PTF should it retain (VirtualColumness)?","if (converter.getWindowFunctionSpec() != null) {",301,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveOpConverter.java
"//  TODO : verify if any quoting is needed for keys","sb.append('=');",202,0.7843137254901961,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/repl/ReplicationUtils.java
"// todo: this should check that the job actually completed and likely use completion time","//which is not tracked directly but available on /jobs/<id> node via "mtime" in Stat",163,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/ZooKeeperCleanup.java
"//  TODO: move this to logicalEquals","if (op1 instanceof ReduceSinkOperator) {",1061,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java
"/*  * TODO:<br> * 1. Could we use combined RR instead of list of RR ?<br> * 2. Use Column Processing from TypeCheckProcFactory<br> * 3. Why not use GB expr ?  */","public class JoinCondTypeCheckProcFactory extends TypeCheckProcFactory {",50,0.5202312138728323,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/JoinCondTypeCheckProcFactory.java
"//  TODO: Temporary for debugging. Doesn't interfere with MTT failures (unlike LOG.debug).","private final static class CasLog {",286,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/common/src/java/org/apache/hive/common/util/FixedSizedObjectPool.java
"//  TODO Deprecation reason does not seem to reflect in the config ?   The ordering is important in case of keys which are also deprecated.   Unset will unset the deprecated keys and all its variants.","final String mrValue = conf.get(dep.getKey());",551,0.5092592592592593,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
"//  GrpSet Col already part of input RS   TODO: Can't we just copy the ExprNodeDEsc from input (Do we need to   explicitly set table alias to null & VC to false","gbKeys.addAll(ExprNodeDescUtils.genExprNodeDesc(rs, groupingSetsColPosition,",868,0.3974358974358974,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveGBOpConvUtil.java
"// todo: DataOperationType is set conservatively here, we'd really want to distinguish update/delete  and insert/select and if resource (that is written to) is ACID or not","if (sinks.contains(table)) {",184,0.7553648068669528,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/client/lock/Lock.java
"//  TODO [MM gap]: CTAS may currently be broken. It used to work. See the old code, and why isCtas isn't used?","public static boolean isInsertOnlyTable(Map<String, String> params, boolean isCtas) {",1516,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/AcidUtils.java
"// todo: add partitioned table that needs conversion to MM/Acid","//todo: rename files case",99,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/upgrade-acid/src/test/java/org/apache/hadoop/hive/upgrade/acid/TestUpgradeTool.java
"//  TODO: Do we really need all this nonsense?","if (session != null) {",645,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
"//  This is bad, but we have to sort the keys of the maps in order   to be commutative.","TreeMap<Object, Object> tm1 = new TreeMap<Object, Object>(m1);",177,0.8620689655172413,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/DataType.java
"// @TODO this seems to be the same as org.apache.hadoop.hive.ql.parse.CalcitePlanner.TableType.DRUID do we really need both","private enum TableType {",440,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveMaterializedViewsRegistry.java
"//  TODO: NPE should not be thrown.","client.add_partitions_pspec(null);",176,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestAddPartitionsFromPartSpec.java
"/*  * Tests for the worker thread and its MR jobs. * todo: most delta files in this test suite use txn id range, i.e. [N,N+M] * That means that they all look like they were created by compaction or by streaming api. * Delta files created by SQL should have [N,N] range (and a suffix in v1.3 and later) * Need to change some of these to have better test coverage.  */","too long.",0,0,0
"//  not good if we reach here, this was initialized at setMetaStoreHandler() time.   this means handler.getWh() is returning null. Error out.","throw new IllegalStateException("Uninitialized Warehouse from MetastoreHandler");",95,0.7379679144385026,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java
"/*  * The processor context for partition pruner. This contains the table alias * that is being currently processed. * TODO: this class may be not useful.  */","public class LBExprProcCtx implements NodeProcessorCtx{",26,0.3875,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBExprProcCtx.java
"//  @deprecated in favour of {@link HCatTable.#nullDefinedAs()}. To be removed in Hive 0.16.","public Builder nullDefinedAs(char nullChar) {",414,0.9349112426035503,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: enable this for production debug, switching between two small buffers?  new CasLog();","private final static CasLog casLog = null; //new CasLog();",1588,0.918918918918919,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cache/BuddyAllocator.java
"/*  * A helper class to isolate newer HBase features from users running against older versions of * HBase that don't provide those features. * * TODO: remove this class when it's okay to drop support for earlier version of HBase.  */","public class HBaseTableSnapshotInputFormatUtil {",33,0.582089552238806,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseTableSnapshotInputFormatUtil.java
"//  NOTE: For Uniform Hash or no buckets/partitions, when the key is empty, we will use the VectorReduceSinkEmptyKeyOperator instead.","replicas,",195,0.176,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/druid-handler/src/java/org/apache/hadoop/hive/druid/json/KafkaSupervisorReport.java
"//  TODO: verify if this is needed","if (lastReduceKeyColName != null) {",909,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveGBOpConvUtil.java
"//  TODO: this class is completely unnecessary... 1-on-1 mapping with parent.","//       Remains here as the legacy of the original higher-level interface (getInstance).",243,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapZookeeperRegistryImpl.java
"/*    * If moving across different FileSystems or differnent encryption zone, need to do a File copy instead of rename.   * TODO- consider if need to do this for different file authority.   * @throws HiveException    */","* @throws IOException",109,0.2153846153846154,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/session/HiveSessionImplwithUGI.java
"//  TODO: support propagation for partitioning/ordering in windowing","containsWindowing = true;",227,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRelColumnsAlignment.java
"//  named columns join   TODO: we can also do the same for semi join but it seems that other   DBMS does not support it yet.","if (joinCond.getType() == HiveParser.TOK_TABCOLNAME",2420,0.3185840707964602,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"/*  * Helper class that generates SQL queries with syntax specific to target DB * todo: why throw MetaException?  */","@VisibleForTesting",34,0.7974683544303798,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/tools/SQLGenerator.java
"//  We can continue   TODO: Need to check that this is the same MV that we are rebuilding","super.visit(node, ordinal, parent);",92,0.35714285714285715,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/MaterializedViewRewritingRelVisitor.java
"//  Guess if CommonJoinResolver will work. If CommonJoinResolver may   convert a join operation, correlation optimizer will not merge that join.   TODO: If hive.auto.convert.join.noconditionaltask=true, for a JoinOperator   that has both intermediate tables and query input tables as input tables,   we should be able to guess if this JoinOperator will be converted to a MapJoin   based on hive.auto.convert.join.noconditionaltask.size.","too long.",0,0,0
"//  TODO: could we log in from ticket cache instead? no good method on UGI right now.","return SHIMS.cloneUgi(baseUgi);",45,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/security/LlapUgiFactoryFactory.java
"//  TODO: support for binary spec? presumably we'd parse it somewhere earlier","return vertex;",610,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java
"//  redundant TODO: callers of this often get part_vals out of name for no reason...","String name =",2511,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO MS-SPLIT for now, keep a copy of HiveConf around as we need to call other methods with   it. This should be changed to Configuration once everything that this calls that requires   HiveConf is moved to the standalone metastore.","conf = (configuration instanceof HiveConf) ? (HiveConf)configuration :",67,0.5671641791044776,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/txn/compactor/CompactorThread.java
"/*    * Closes the client releasing any {@link IMetaStoreClient meta store} connections held. Does not notify any open   * transactions (TODO: perhaps it should?)    */","@Override",127,0.8275862068965517,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/streaming/src/java/org/apache/hive/hcatalog/streaming/mutate/client/MutatorClient.java
"//  TODO: will this work?","ecode = qt.executeClient(versionFile, fname);",141,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreCompareCliDriver.java
"//  We don't have the entire part; copy both whatever we intended to cache, and the rest,   to an allocated buffer. We could try to optimize a bit if we have contiguous buffers   with gaps, but it's probably not needed.","if (candidateCached != null) {",1128,0.582995951417004,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"/*      * TODO: Hack fix until HIVE-5848 is addressed. non-exact type shouldn't be promoted     * to exact type, as FunctionRegistry.getCommonClass() might do. This corrects     * that.      */","if (commonTypeInfo instanceof DecimalTypeInfo) {",238,0.6454545454545455,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java
"//  FIXME: old implementation returned null; exception maybe?","return null;",424,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/HiveFileFormatUtils.java
"//  Optimize the scenario when there are no grouping keys - only 1 reducer is needed","int numReducers = -1;",5828,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  TODO: is Decimal an exact numeric or approximate numeric?","case DECIMAL:",632,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
"//  TODO: why doesn't this use one of the existing options implementations?!","enum OptionConstants {",42,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cli/LlapStatusOptionsProcessor.java
"//  Ensure there's no threadlocal. We don't expect one.   We don't ever want to create key paths with world visibility. Why is that even an option?!!","None",None,None,None
"/*    * todo: when job is complete, should print the msgCount table to log     */","private static final class DataLossLogger {",643,0.9655172413793104,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hive/hcatalog/pig/HCatBaseStorer.java
"//  TODO explain should use a FetchTask for reading","for (Task<? extends Serializable> task : plan.getRootTasks()) {",2971,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
"//  This detail not desired.","invokeFlag = false;",717,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/ExplainTask.java
"//  TODO: use the other HdfsUtils here","if (!(fs instanceof DistributedFileSystem)) return;",110,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/FileMetadataManager.java
"//  First, check if the registry has been updated since the error, and skip the error if   we have received new, valid registry info (TODO: externally, add a grace period for this?).","Ref<Integer> endpointVersion = new Ref<>(-1);",929,0.6484018264840182,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
"//  TODO: calculate from cached values.","public List<ColumnStatistics> getPartitionColumnStatistics(String catName, String dbName, String tblName,",1717,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java
"//  Array size not big enough?","if (startPosition == null || arrayLength + 1 == startPosition.length) {",130,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyArray.java
"//  UNDONE: Needed to longTest?","case BINARY:",240,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/util/batchgen/VectorColumnGroupGenerator.java
"//  TODO Reduce the number of lookups that happen here. This shouldn't go to HDFS for each call.","// The hiveJarDir can be determined once per client.",792,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
"//  No data to read for this stripe. Check if we have some included index-only columns.   TODO: there may be a bug here. Could there be partial RG filtering on index-only column?","if (hasIndexOnlyCols && (rgs == null)) {",363,0.6604651162790698,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"//  FIXME. Do the right thing Luke.","if (getContext() == null) {",180,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/HiveSplitGenerator.java
"//  TODO make it so I can randomize the column order","StringBuilder buf = new StringBuilder();",321,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/StreamingIntegrationTester.java
"//  TODO: right now we treat each slice as a stripe with a single RG and never bother         with indexes. In phase 4, we need to add indexing and filtering.","@Override",468,0.7165775401069518,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
"//  TODO: a pattern from Curator. Better error handling?","return;",262,0.7899159663865546,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/SlotZnode.java
"//  IO thread pool. Listening is used for unhandled errors for now (TODO: remove?)","int numThreads = HiveConf.getIntVar(conf, HiveConf.ConfVars.LLAP_IO_THREADPOOL_SIZE);",192,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/api/impl/LlapIoImpl.java
"//  Now, we need to look for any values that the user set that MetastoreConf doesn't know about.   TODO Commenting this out for now, as it breaks because the conf values aren't getting properly   interpolated in case of variables.  See HIVE-17788.","too long.",0,0,0
"//  FIXME: including this in the signature will almost certenly differ even if the operator is doing the same   there might be conflicting usages of logicalCompare?","public String getStatsAggPrefix() {",421,0.7964601769911505,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/FileSinkDesc.java
"//  MultiMRInput may not. Fix once TEZ-3302 is resolved.","processorContext.waitForAllInputsReady(li);",509,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MapRecordProcessor.java
"//  Preempt only if there are no pending preemptions on the same host   When the premption registers, the request at the highest priority will be given the slot,   even if the initial preemption was caused by some other task.   TODO Maybe register which task the preemption was for, to avoid a bad non-local allocation.","too long.",0,0,0
"//  TODO: this is wrong; this test sets up dummy txn manager and so it cannot create ACID tables.         This used to work by accident, now this works due a test flag. The test needs to be fixed.         Also applies for a couple more tests.",".run("create table t1 (i int, j int) partitioned by (load_date date) "",455,0.6023166023166023,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hadoop/hive/ql/parse/TestReplicationScenariosAcrossInstances.java
"//  TODO: why is this needed? we could just save the host and port?","File qf = new File(outDir, fileName);",1304,0.6052631578947368,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  TODO There needs to be a mechanism to figure out different attempts for the same task. Delays   could potentially be changed based on this.","@VisibleForTesting",2764,0.8102564102564103,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"// it's not wrong to take all delete events for bucketed tables but it's more efficient  to only take those that belong to the 'bucket' assuming we trust the file name  un-bucketed table - get all files","FileSystem fs = deltaDirectory.getFileSystem(conf);",1278,0.6101694915254238,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java
"/*        * Determine an *initial* input vector expression.       *       * Note: we may have to convert it later from DECIMAL_64 to regular decimal.        */","inputExpression =",4254,0.5620915032679739,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
"//  Note - this is a little bit confusing; the special treatment of stripe-level buffers   is because we run the ColumnStreamData refcount one ahead (as specified above). It   may look like this would release the buffers too many times (one release from the   consumer, one from releaseInitialRefcounts below, and one here); however, this is   merely handling a special case where all the batches that are sharing the stripe-   level stream have been processed before we got here; they have all decRef-ed the CSD,   but have not released the buffers because of that extra refCount. So, this is   essentially the "consumer" refcount being released here.","too long.",0,0,0
"//  this doesn't always work, since some JDBC drivers (e.g.,   Oracle's) return a blank string from getTableName.","String table = rsMeta.getTableName(col + 1);",83,0.6944444444444444,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/beeline/src/java/org/apache/hive/beeline/Rows.java
"//  TODO: Can this be moved out of the main callback path","RPC.stopProxy(umbilical);",442,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskRunnerCallable.java
"// TODO: add more expected test result here","});",252,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QOutProcessor.java
"//  TODO MS-SPLIT - for now we have construct this by reflection because IMetaStoreClient   can't be   moved until after HiveMetaStore is moved, which can't be moved until this is moved.","Class<? extends MetaException> exClass = JavaUtils.getClass(",52,0.6607929515418502,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/PartFilterExprUtil.java
"// todo: need a test where we actually have more than 1 file","return deltaFiles;",1287,0.9896907216494846,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcRawRecordMerger.java
"//  Here comes the ugly part...","long partitionId = extractSqlLong(fields[0]);",659,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/MetaStoreDirectSql.java
"//  To be removed in Hive 0.16.","public Builder bucketCols(List<String> bucketCols, int buckets) {",286,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  OPTIMIZATION for later.","// if (oi instanceof TypeInfoBasedObjectInspector) {",760,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java
"//  Is there a way to provide char length here?   It might actually be ok as long as there is an object inspector (with char length)   receiving this value.","result = new HiveVarchar();",1007,0.4625,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java
"//  This command exists solely to output this message. TODO: can we do it w/o an error?","throw new SemanticException("Activate a resource plan to enable workload management");",954,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
"//  TODO: Add support for AND clauses under OR clauses   first-cut takes a known minimal tree and no others.   $expr = (a=1)           (a=1 or a=2)           (a in (1,2))           ($expr and *)","//         (* and $expr)",176,0.5086705202312138,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/FixedBucketPruningOptimizer.java
"//  TODO: Set this up as a tree, instead of a flat list.","Map<String, ModuleConfig> moduleConfigs = extractModuleConfigs();",146,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/conf/UnitTestPropertiesParser.java
"/*  * Operator factory for predicate pushdown processing of operator graph Each * operator determines the pushdown predicates by walking the expression tree. * Each operator merges its own pushdown predicates with those of its children * Finally the TableScan operator gathers all the predicates and inserts a * filter operator after itself. TODO: Further optimizations 1) Multi-insert * case 2) Create a filter operator for those predicates that couldn't be pushed * to the previous operators in the data flow 3) Merge multiple sequential * filter predicates into so that plans are more readable 4) Remove predicates * from filter operators that have been pushed. Currently these pushed * predicates are evaluated twice.  */","too long.",0,0,0
"//  HIVE-12244 call currently ineffective","work.getPartitionDescs().remove(desc);",236,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/spark/SparkDynamicPartitionPruner.java
"//  Note: no location check; the buffer is always locked for move here.","if (assertsEnabled) {",966,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cache/BuddyAllocator.java
"//  TODO MS-SPLIT For now if we cannot load the default PartitionExpressionForMetastore   class (since it's from ql) load the DefaultPartitionExpressionProxy, which just throws   UnsupportedOperationExceptions.  This allows existing Hive instances to work but also   allows us to instantiate the metastore stand alone for testing.  Not sure if this is   the best long term solution.","too long.",0,0,0
"//  TODO: this is very brittle given that Hive supports nested directories in the tables.         The caller should pass a flag explicitly telling us if the directories in the         input are data, or parent of data. For now, retain this for backward compat.","too long.",0,0,0
"//  TODO: these appear to always be called under write lock. Do they need sync?","synchronized void setAssignmentInfo(NodeInfo nodeInfo, ContainerId containerId, long startTime) {",2832,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  TODO: we could perhaps reuse the same directory for HiveResources?","Path scratchDir = utils.createTezDir(ctx.getMRScratchDir(), conf);",178,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezTask.java
"/*    * If there's a mismatch between static and object name, or a mismatch between   * vector and non-vector operator name, the optimizer doens't work correctly.    */","public void testOperatorNames() throws Exception {",70,0.6464646464646465,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/TestOperatorNames.java
"//  Not really sure how to refer to this (or if we can).   TODO: We could find a different from branch for the union, that might have an alias?         Or we could add an alias here to refer to, but that might break other branches.","LOG.debug("Replacing SETCOLREF with ALLCOLREF because of the nested node "",482,0.3926940639269406,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
"//  TODO : instantiating FS objects are generally costly. Refactor","FileSystem fs = dbRoot.getFileSystem(conf);",273,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/ReplDumpTask.java
"//  TODO: when PB is upgraded to 2.6, newInstance(ByteBuffer) method should be used here.","CodedInputStream cis = CodedInputStream.newInstance(",1527,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"/*  All the code paths below propagate nulls even if neither arg2 nor arg3     * have nulls. This is to reduce the number of code paths and shorten the     * code, at the expense of maybe doing unnecessary work if neither input     * has nulls. This could be improved in the future by expanding the number     * of code paths.      */","too long.",0,0,0
"//  @deprecated in favour of {@link HCatPartition.#getPartitionKeyValMap()}. To be removed in Hive 0.16.","public Map<String, String> getPartitionSpec() {",81,0.9430051813471503,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatAddPartitionDesc.java
"// TODO: Remove this once Calcite FilterProjectTransposeRule can take rule operand","public class HiveFilterProjectTSTransposeRule extends RelOptRule {",39,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveFilterProjectTSTransposeRule.java
"//  TODO: we could fall back to trying one by one and only ignore the failed ones.","logRefreshError("Unable to localize jars: ", jars, t);",231,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/FunctionLocalizer.java
"//  @deprecated in favour of {@link HCatTable.#getStorageHandler()}. To be removed in Hive 0.16.","public String getStorageHandler() {",157,0.9378531073446328,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  First try temp table   TODO CAT - I think the right thing here is to always put temp tables in the current   catalog.  But we don't yet have a notion of current catalog, so we'll have to hold on   until we do.","org.apache.hadoop.hive.metastore.api.Table table = getTempTable(dbname, name);",128,0.2087912087912088,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/SessionHiveMetaStoreClient.java
"// TODO: set other Table properties as needed","//authorize against the table operation so that location permissions can be checked if any",193,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/SemanticAnalysis/CreateTableHook.java
"//  Don't pass in the pool set - not thread safe; if the user is trying to force us to   use a non-existent pool, we want to fail anyway. We will fail later during get.","String mappedPool = mapping.mapSessionToPoolName(input, allowAnyPool, null);",2123,0.6700507614213198,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
"// TODO: Since OperationLog is moved to package o.a.h.h.ql.session,   we may add a Enum there and map FetchOrientation to it.","if (fetchOrientation.equals(FetchOrientation.FETCH_FIRST)) {",345,0.7239263803680982,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
"//  TODO: ideally this only needs to be called if the result   type will also change. However, since that requires   support from type inference rules to tell whether a rule   decides return type based on input types, for now all   operators will be recreated with new type if any operand   changed, unless the operator has "built-in" type.","too long.",0,0,0
"//  TODO: ideally we should store shortened representation of only the necessary fields         in HBase; it will probably require custom SARG application code.","OrcTail orcTail = ReaderImpl.extractFileTail(fileMetadata);",44,0.729064039408867,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcFileFormatProxy.java
"//  This is a massive hack.  The compactor threads have to access packages in ql (such as   AcidInputFormat).  ql depends on metastore so we can't directly access those.  To deal   with this the compactor thread classes have been put in ql and they are instantiated here   dyanmically.  This is not ideal but it avoids a massive refactoring of Hive packages.     Wrap the start of the threads in a catch Throwable loop so that any failures   don't doom the rest of the metastore.","too long.",0,0,0
"//  FIXME: there were 2 afterclass methods...i guess this is the right order...maybe not","qt.shutdown();",95,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/CoreHBaseCliDriver.java
"//  TODO HIVE-13483 Get all of these properties from the registry. This will need to take care of different instances   publishing potentially different values when we support changing configurations dynamically.","// For now, this can simply be fetched from a single registry instance.",329,0.7003610108303249,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"//  TODO: replace with withTimeout after we get the relevant guava upgrade.","this.timeoutTimer = timeoutPool.schedule(",99,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WmTezSession.java
"/*    * TODO: need to turn on rules that's commented out and add more if necessary.    */","@Override",340,0.9692307692307692,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/spark/SparkCompiler.java
"/* todo: handle renaming files somewhere */","}",253,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/upgrade-acid/src/main/java/org/apache/hadoop/hive/upgrade/acid/UpgradeTool.java
"//  @deprecated in favour of {@link HCatTable.#getBucketCols()}. To be removed in Hive 0.16.","public List<String> getBucketCols() {",132,0.9349112426035503,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: this doesn't include superclass.","Field[] fields = c.getDeclaredFields();",209,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/VerifyingObjectStore.java
"//  FIXME: move this to ColStat related part","if (!work.isExplicitAnalyze() && !followedColStats1) {",140,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/stats/BasicStatsTask.java
"//  TODO: Not sure that this is the correct behavior. It doesn't make sense to create the   partition without column info. This should be investigated later.","Partition part =",330,0.7164179104477612,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestAddPartitions.java
"//  Note : preservePartitionSpecs=true implies inheritTableSpecs=false but   but preservePartitionSpecs=false(default) here is not sufficient enough   info to set inheritTableSpecs=true","loadTableWork.setInheritTableSpecs(false);",406,0.5826086956521739,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
"//  FIXME: this should be changeto valueOf ...   that will also kill that fallback 'none' which is I think more like a problem than a   feature ;)","clusterType = MiniClusterType.valueForString(modeStr);",346,0.49673202614379086,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/cli/control/AbstractCliConfig.java
"//  TODO Setup a set of threads to process incoming requests.   Make sure requests for a single dag/query are handled by the same thread","private static final Logger LOG = LoggerFactory.getLogger(ContainerRunnerImpl.class);",98,0.625,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/ContainerRunnerImpl.java
"//  TODO: add alter database support in HCat","// Table operations.",322,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/SemanticAnalysis/HCatSemanticAnalyzer.java
"//  TODO add tests for partitions in other catalogs","@Test(expected = NullPointerException.class)",171,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestAddPartitionsFromPartSpec.java
"//  TODO I suspect we could skip much of the stuff above this in the function in the case   of update and delete.  But I don't understand all of the side effects of the above   code and don't want to skip over it yet.","// Find the bucket id, and switch buckets if need to",991,0.5882352941176471,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java
"//  TODO: expireAfterAccess locks cache segments on put and expired get. It doesn't look too bad,         but if we find some perf issues it might be a good idea to remove this - we are probably         not caching that many constructors.   Note that weakKeys causes "==" to be used for key compare; this will only work   for classes in the same classloader. Should be ok in this case.","too long.",0,0,0
"//  TODO Why is the queue name set again. It has already been setup via setQueueName. Do only one of the two.","String confQueueName = conf.get(TezConfiguration.TEZ_QUEUE_NAME);",262,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
"//  TODO Create and init session sets up queue, isDefault - but does not initialize the configuration","private TezSessionPoolSession createAndInitSession(",211,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionPoolManager.java
"//  @deprecated in favour of {@link HCatTable.#sortCols(Map<String, String>)}.   To be removed in Hive 0.16.","None",None,None,None
"//  TODO: Handle Query Hints; currently we ignore them","boolean selectStar = false;",4351,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"//  TODO: Currently we only support EQUAL operator on two references.   We might extend the logic to support other (order-preserving)   UDFs here.","RexCall equals = (RexCall) conj;",146,0.651685393258427,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRelColumnsAlignment.java
"//  is the right was at the left side of a right outer join?","if (!leftPosListOfLastRightOuterJoin.contains(condn.getRight())) {",549,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/MapJoinProcessor.java
"//  TODO: why does this only kill non-default sessions?   Nothing for workload management since that only deals with default ones.","TezSessionPoolManager.getInstance().closeNonDefaultSessions();",94,0.5974025974025974,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/monitoring/TezJobMonitor.java
"//  TODO: should this use getPartitionDescFromPathRecursively? That's what other code uses.","PartitionDesc partDesc = pathToPartitionInfo.get(path);",1646,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/Vectorizer.java
"//  TODO: Fix this","List<String> materializedViews = getTables(dbName, ".*", TableType.MATERIALIZED_VIEW);",1034,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java
"//  ### FIXME: doing the multi-line handling down here means   higher-level logic never sees the extra lines. So,   for example, if a script is being saved, it won't include   the continuation lines! This is logged as sf.net   bug 879518.","// use multiple lines for statements not terminated by the delimiter",1183,0.4149377593360996,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/beeline/src/java/org/apache/hive/beeline/Commands.java
"//  REVIEW jhyde 29-Oct-2007: This rule is non-static, depends on the state   of members in RelDecorrelator, and has side-effects in the decorrelator.   This breaks the contract of a planner rule, and the rule will not be   reusable in other planners.","too long.",0,0,0
"//  We can loop thru all the tables to check if they are ACID first and then perform cleanup,   but it's more efficient to unconditionally perform cleanup for the database, especially   when there are a lot of tables","txnHandler = getTxnHandler();",54,0.5967741935483871,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/AcidEventListener.java
"//  TODO: Implement this","private static ExprNodeDesc propConstDistUDAFParams() {",1281,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/HiveGBOpConvUtil.java
"//  TODO: allow using unsafe optionally.   bounds check first, to trigger bugs whether the first byte matches or not","if (left[leftOffset + length - 1] != rightBuffer[rightFrom + length - 1]) {",305,0.5271317829457365,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/WriteBuffers.java
"//  TODO: this doesn't appear to be used anywhere.","public EmbeddedCLIServiceClient(ICLIService cliService, Configuration conf) {",36,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
"//  for auto convert map-joins, it not safe to dedup in here (todo)","boolean mergeJoins = !pctx.getConf().getBoolVar(HIVECONVERTJOIN) &&",75,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/correlation/ReduceSinkDeDuplication.java
"//  We're scanning a tree from roots to leaf (this is not technically   correct, demux and mux operators might form a diamond shape, but   we will only scan one path and ignore the others, because the   diamond shape is always contained in a single vertex). The scan   is depth first and because we remove parents when we pack a pipeline   into a vertex we will never visit any node twice. But because of that   we might have a situation where we need to connect 'work' that comes after   the 'work' we're currently looking at.     Also note: the concept of leaf and root is reversed in hive for historical","too long.",0,0,0
"//  The following parameters are not supported yet. TODO Add support","private static final String APPLY_PATCH_SCRIPT_PATH = "applyPatchScriptPath";",61,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/testutils/ptest2/src/main/java/org/apache/hive/ptest/execution/conf/TestConfiguration.java
"//  TODO: this should be   unique","None",None,None,None
"// todo: Concurrent insert/update of same partition - should pass","private List<ShowLocksResponseElement> getLocksWithFilterOptions(HiveTxnManager txnMgr,",1641,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/lockmgr/TestDbTxnManager2.java
"//  @deprecated in favour of {@link HCatTable.#fieldsTerminatedBy()}. To be removed in Hive 0.16.","public Builder fieldsTerminatedBy(char delimiter) {",379,0.9385474860335196,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: this is invalid for ACID tables, and we cannot access AcidUtils here.","populateQuickStats(fileStatus, params);",804,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java
"/*    * After each major compaction, stats need to be updated on each column of the   * table/partition which previously had stats.   * 1. create a bucketed ORC backed table (Orc is currently required by ACID)   * 2. populate 2 partitions with data   * 3. compute stats   * 4. insert some data into the table using StreamingAPI   * 5. Trigger major compaction (which should update stats)   * 6. check that stats have been updated   *   * @throws Exception todo:   *                   2. add non-partitioned test   *                   4. add a test with sorted table?    */","too long.",0,0,0
"/*    * in Hive 1.3.0 delta file names changed to delta_xxxx_yyyy_zzzz; prior to that   * the name was delta_xxxx_yyyy.  We want to run compaction tests such that both formats   * are used since new (1.3) code has to be able to read old files.    */","abstract boolean useHive130DeltaDirName();",572,0.5134099616858238,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/txn/compactor/CompactorTest.java
"//  TODO: should call HiveHFileOutputFormat#setOutputPath","jobProperties.put("mapred.output.dir", path);",276,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
"//  TODO: we could try to get superclass or generic interfaces.","LOG.trace("Non-parametrized map type: {}", field);",261,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/storage-api/src/java/org/apache/hadoop/hive/ql/util/IncrementalObjectSizeEstimator.java
"//  TODO: this actually calls the metrics system and getMetrics - that may be expensive.         For now it looks like it should be ok to do on WM thread.","this.metrics = ms == null ? null : WmPoolMetrics.create(fullName, ms);",1741,0.7684210526315789,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/WorkloadManager.java
"//  TODO: get rid of the builders - they serve no purpose... just call ctors directly.","switch (schema.getCategory()) {",2329,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedTreeReaderFactory.java
"//  TODO: Verify GB having is not a separate filter (if so we shouldn't   introduce derived table)","if (parent instanceof Filter || parent instanceof Join || parent instanceof SetOp ||",295,0.8382352941176471,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/PlanModifierForASTConv.java
"/* Q: why don't we lock the snapshot here???  Instead of having client make an explicit call    whenever it chooses    A: If we want to rely on locks for transaction scheduling we must get the snapshot after lock    acquisition.  Relying on locks is a pessimistic strategy which works better under high    contention. */","too long.",0,0,0
"//  TODO: temporary, need to expose from ORC utils (note the difference in null checks)","static DiskRangeList planIndexReading(TypeDescription fileSchema,",2036,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"//  TODO: maybe use stack of est+obj pairs instead of recursion.","if (fields == null) {",391,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/storage-api/src/java/org/apache/hadoop/hive/ql/util/IncrementalObjectSizeEstimator.java
"//  TODO: shortcut for last col below length?","try {",148,0.7474747474747475,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/BatchToRowReader.java
"//  TEMPORARY: In order to avoid a new version of storage-api, do the conversion here...","byte[] floatBytes = Float.toString((float) inV.vector[i]).getBytes();",45,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/expressions/CastFloatToDecimal.java
"// TODO: these constraints should be supported for partition columns","throw new SemanticException(",13072,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  We have a nested setcolref. Process that and start from scratch TODO: use stack?","processSetColsNode((ASTNode)child, searcher);",448,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java
"//  TODO: is this correct? based on the same logic as HIVE-14200","reduceWork.getEdgePropRef().setAutoReduce(null, false, 0, 0, 0);",196,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/LlapDecider.java
"//  TODO refactor the following into the pipeline","ChannelFuture lastMap = null;",791,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/ShuffleHandler.java
"//  TODO: change to FileInputFormat.... field after MAPREDUCE-7086.","nonRecConf.setBoolean("mapreduce.input.fileinputformat.input.dir.nonrecursive.ignore.subdirs", true);",553,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
"//  TODO: if we ever use this endpoint for anything else, refactor cycling into a separate class.","int urlIx = lastKnownGoodUrl, lastUrlIx = ((urlIx == 0) ? rmNodes.length : urlIx) - 1;",58,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/YarnQueueHelper.java
"//  something is seriously wrong if this is happening","throw new HiveException(ErrorMsg.GENERIC_ERROR.getErrorCodedMsg());",1340,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/DagUtils.java
"//  TODO: Ordering seems to affect the distinctness, needs checking, disabling.","/*",3058,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO: avoid put() by working directly in OutStream?","if (LlapIoImpl.LOG.isTraceEnabled()) {",622,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/SerDeEncodedDataReader.java
"//  Can't fetch prefix on colqual, must pull the entire qualifier   TODO use an iterator to do the filter, server-side.","pairs.add(new Pair<Text,Text>(new Text(mapMapping.getColumnFamily()), null));",394,0.7152317880794702,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/mr/HiveAccumuloTableInputFormat.java
"//  These tests inherently cause exceptions to be written to the test output   logs. This is undesirable, since you it might appear to someone looking   at the test output logs as if something is failing when it isn't. Not   sure","// how to get around that.",1029,0.5121951219512195,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-unit/src/test/java/org/apache/hive/jdbc/cbo_rp_TestJdbcDriver2.java
"//     return HiveConf.getPositionFromInternalName(fieldName);   The above line should have been all the implementation that   we need, but due to a bug in that impl which recognizes   only single-digit columns, we need another impl here.","Pattern internalPattern = Pattern.compile("_col([0-9]+)");",226,0.4444444444444444,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java
"//  @deprecated in favour of {@link HCatTable.#getPartCols()}. To be removed in Hive 0.16.","public List<HCatFieldSchema> getPartitionCols() {",122,0.9333333333333333,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: Verify if we need to use ConstantObjectInspector to unwrap data","switch (hiveTypeCategory) {",615,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
"//  2) Generate HiveTableFunctionScan RelNode for lateral view   TODO: Support different functions (not only INLINE) with LATERAL VIEW JOIN","// ^(TOK_LATERAL_VIEW ^(TOK_SELECT ^(TOK_SELEXPR ^(TOK_FUNCTION Identifier["inline"] valuesClause) identifier* tableAlias)))",3096,0.627906976744186,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"// todo: this is actually not adding anything since LockComponent uses a Trie to "promote" a lock  except by accident - when we have a partitioned target table we have a ReadEntity and WriteEntity  for the table, so we mark ReadEntity and then delete WriteEntity (replace with Partition entries)  so DbTxnManager skips Read lock on the ReadEntity....  input.noLockNeeded()?","too long.",0,0,0
"// TODO- cleanup once parquet support Timestamp type annotation.","return ETypeConverter.ETIMESTAMP_CONVERTER.getConverter(type, index, parent, hiveTypeInfo);",395,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java
"//  TODO: buffers are accounted for at allocation time, but ideally we should report the memory         overhead from the java objects to memory manager and remove it when discarding file.","if (data.stripes == null || data.stripes.isEmpty()) {",503,0.6899563318777293,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cache/SerDeLowLevelCacheImpl.java
"//  TODO: cleanup this","if (qb.getParseInfo().getAlias() != null) {",4890,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"//  TODO: HIVE-13624 Do we need maxLength checking?","byte[] bytes = hiveVarchar.getValue().getBytes();",489,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/VectorAssignRow.java
"//  In addBatchToWriter, we have passed the batch to both ORC and operator pipeline   (neither ever changes the vectors). We'd need a set of vectors batch to write to.   TODO: for now, create this from scratch. Ideally we should return the vectors from ops.         We could also have the ORC thread create it for us in its spare time...","too long.",0,0,0
"//  TODO: enforce max length","return value;",46,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java
"//  TODO: would it make sense to return buffers asynchronously?","@Override",233,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cache/BuddyAllocator.java
"//  TODO: The best solution is to support NaN in expression reduction.","if (Double.isNaN((Double) value)) {",678,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
"//  TODO: ideally, this should be moved outside to HiveMetaStore to be shared between         all the RawStore-s. Right now there's no method to create a pool.","if (defaultPoolSize > 0) {",10927,0.7244897959183674,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO HIVE-14042. Abort handling.","perfLogger.PerfLogBegin(CLASS_NAME, PerfLogger.TEZ_INIT_OPERATORS);",76,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/MergeFileRecordProcessor.java
"// todo: update to search by ID once HIVE-13353 is done","ShowCompactResponse allCompactions = db.showCompactions();",2127,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  Note: type param is not available here.","PrimitiveTypeEntry typeEntry = getTypeFor(method.getReturnType());",97,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java
"//  TODO: When function privileges are implemented, they should be deleted here.","pm.deletePersistentAll(mfunc);",9336,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO: perhaps move to Orc InStream?","private static class IndexStream extends InputStream {",1788,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/encoded/EncodedReaderImpl.java
"// TODO: should not throw different exceptions for different HMS deployment types","}",309,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestListPartitions.java
"//  TODO: Clean up all the other paths that are created.","FunctionRegistry.unregisterTemporaryUDF("test_udaf");",1135,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  TODO: ideally when col-stats-accurate stuff is stored in some sane structure, this should         to retrieve partsToUpdate in a single query; no checking partition params in java.","List<String> partNames = null;",268,0.6929824561403509,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUpdaterThread.java
"//  UNDONE: Missing date/time interval data types","public enum GenerateCategory {",38,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/util/batchgen/VectorBatchGenerator.java
"//  @deprecated in favour of {@link HCatTable.#getCols()}. To be removed in Hive 0.16.","public List<HCatFieldSchema> getCols() {",112,0.9299363057324841,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: refactor this out","if (pathToPartInfo == null) {",74,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/CombineHiveRecordReader.java
"//  TODO This needs to be looked at. Map of Map to Map... Made concurrent for now since split generation   can happen in parallel.","private static final Map<Map<Path, PartitionDesc>, Map<Path, PartitionDesc>> cache =",61,0.8936170212765957,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/SplitGrouper.java
"//  TODO: Fix the expressions later.","old_dep.setExpr(null);",160,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/lineage/LineageCtx.java
"//  @deprecated in favour of {@link #create(HCatTable)}. To be removed in Hive 0.16.","public static Builder create(String dbName, String tableName, List<HCatFieldSchema> columns) {",56,0.9281045751633987,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatCreateTableDesc.java
"//  TODO: handle ExprNodeColumnListDesc","}",185,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/RexNodeConverter.java
"//  5. Push Down Semi Joins  TODO: Enable this later","/*perfLogger.PerfLogBegin(this.getClass().getName(), PerfLogger.OPTIMIZER);",2029,0.6774193548387096,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java
"// todo: add TXNS.COMMENT filed and set it to 'aborted by system due to timeout'  easier to read logs","Collections.sort(batchToAbort);//easier to read logs",4429,0.8918918918918919,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
"//  TODO RIVEN switch this back to package level when we can move TestHadoopAuthBridge23 into   riven.","// Package permission so that HadoopThriftAuthBridge can construct it but others cannot.",75,0.9629629629629629,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/security/HadoopThriftAuthBridge23.java
"//  TODO Change this over to just store local dir indices, instead of the entire path. Far more efficient.","private final Path indexPath;",1091,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/ShuffleHandler.java
"//  TODO: we might revisit this in create-drop-recreate cases, needs some thinking on.","DDLWork work = new DDLWork(new HashSet<>(), new HashSet<>(), createDbDesc);",131,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/repl/bootstrap/load/LoadDatabase.java
"//  TODO: why is this in text formatter?!!","//       This computes stats and should be in stats (de-duplicated too).",371,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/TextMetaDataFormatter.java
"/*  * NOTE: this rule is replicated from Calcite's SubqueryRemoveRule * Transform that converts IN, EXISTS and scalar sub-queries into joins. * TODO: *  Reason this is replicated instead of using Calcite's is *    Calcite creates null literal with null type but hive needs it to be properly typed * * <p>Sub-queries are represented by {@link RexSubQuery} expressions. * * <p>A sub-query may or may not be correlated. If a sub-query is correlated, * the wrapped {@link RelNode} will contain a {@link RexCorrelVariable} before * the rewrite, and the product of the rewrite will be a {@link Correlate}. * The Correlate can be removed using {@link RelDecorrelator}.  */","too long.",0,0,0
"//  truncate (TODO: posix_fallocate?)","// Use RW, not PRIVATE because the copy-on-write is irrelevant for a deleted file",715,0.7252747252747253,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/cache/BuddyAllocator.java
"//  NOTE: This code tries to get all key-value pairs out of the map.   It's not very efficient. The more efficient way should be to let MapOI   return an Iterator. This is currently not supported by MapOI yet.","Map<?, ?> map = inputOI.getMap(input);",545,0.48868778280542985,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java
"//  UNDONE: Why do we need to specify BinarySortableSerDe explicitly here???","TableDesc keyTableDesc = mapJoinDesc.getKeyTblDesc();",393,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/test/org/apache/hadoop/hive/ql/exec/vector/mapjoin/MapJoinTestConfig.java
"// todo: last param is bogus. why is this hardcoded?","OrcInputFormat.setSearchArgument(readerOptions, schemaTypes, conf, true);",2155,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  TODO: move this to a common method   Note: this gets IDs by name, so we assume indices don't need to be adjusted for ACID.","int[] filterColumns = RecordReaderImpl.mapSargColumnsToOrcInternalColIdx(",303,0.46511627906976744,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/encoded/OrcEncodedDataReader.java
"//  DecorrelateRexShuttle ends up decorrelating expressions cor.col1 <> $4   to $4=$4 if value generator is not generated, $4<>$4 is further simplified   to false. This is wrong and messes up the whole tree. To prevent this visitCall   is overridden to rewrite/simply such predicates to is not null.   we also need to take care that we do this only for correlated predicates and   not user specified explicit predicates   TODO:  This code should be removed once CALCITE-1851 is fixed and   there is support of not equal","too long.",0,0,0
"//  TODO: need proper clone. Meanwhile, let's at least keep this horror in one place","PerfLogger perfLogger = SessionState.getPerfLogger();",625,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/SerializationUtilities.java
"//  Note that we pass job config to the record reader, but use global config for LLAP IO.   TODO: add tracing to serde reader","SerDeEncodedDataReader reader = new SerDeEncodedDataReader(cache, bufferManager, conf,",96,0.8352941176470589,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/io/decode/GenericColumnVectorProducer.java
"//  @deprecated in favour of {@link HCatPartition.#getTableName()}. To be removed in Hive 0.16.","public String getTableName() {",91,0.9371428571428572,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatAddPartitionDesc.java
"//  FIXME: support template types. It currently has conflict with ExprNodeConstantDesc","if (LOG.isDebugEnabled()) {",185,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/ConstantPropagateProcFactory.java
"/*  * This rule is a copy of {@link org.apache.calcite.rel.rules.AggregateReduceFunctionsRule} * that regenerates Hive specific aggregate operators. * * TODO: When CALCITE-2216 is completed, we should be able to remove much of this code and * just override the relevant methods. * * Planner rule that reduces aggregate functions in * {@link org.apache.calcite.rel.core.Aggregate}s to simpler forms. * * <p>Rewrites: * <ul> * * <li>AVG(x) &rarr; SUM(x) / COUNT(x) * * <li>STDDEV_POP(x) &rarr; SQRT( *     (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *    / COUNT(x)) * * <li>STDDEV_SAMP(x) &rarr; SQRT( *     (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *     / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END) * * <li>VAR_POP(x) &rarr; (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *     / COUNT(x) * * <li>VAR_SAMP(x) &rarr; (SUM(x * x) - SUM(x) * SUM(x) / COUNT(x)) *        / CASE COUNT(x) WHEN 1 THEN NULL ELSE COUNT(x) - 1 END * </ul>  */","too long.",0,0,0
"//  TODO: Handle more than 2 inputs for setop","if (!validSetopParent(rel, parent))",148,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/PlanModifierForASTConv.java
"//  TODO: separate model is needed for compressedOops, which can be guessed from memory size.","return JAVA64;",269,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/storage-api/src/java/org/apache/hadoop/hive/ql/util/JavaDataModel.java
"// TODO: Should we convert MultiJoin to be a child of HiveJoin","public class HiveJoin extends Join implements HiveRelNode {",54,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/reloperators/HiveJoin.java
"//  TODO should be doing security check here.  Users should not be   able to see each other's locks.","locks = lockMgr.getLocks(false, isExt);",3008,0.803030303030303,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
"//  We do no handle anything but OK for now. Again, we need a real client for this API.   TODO: handle 401 and return a new connection? nothing for now","InputStream errorStream = connection.getErrorStream();",135,0.7272727272727273,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/YarnQueueHelper.java
"//  TODO: close basically resets the object to a bunch of nulls.         We should ideally not reuse the object because it's pointless and error-prone.","sessionState.close(false);",490,0.6081871345029239,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionPoolManager.java
"// todo: createOptionsForReader() assumes it's !isOriginal.... why?","final Reader.Options readOptions = OrcInputFormat.createOptionsForReader(conf);",2078,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java
"//  TODO: Required due to SessionState.getHDFSSessionPath. Why wasn't it required before?","sessionState.setIsHiveServerQuery(true);",69,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/DriverUtils.java
"//  TODO Change this to not serialize the entire Configuration - minor.","UserPayload servicePluginPayload = TezUtils.createUserPayloadFromConf(tezConfig);",333,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
"//  TODO: For object inspector fields, assigning 16KB for now. To better estimate the memory size every   object inspectors have to implement MemoryEstimate interface which is a lot of change with little benefit compared","// to writing an instrumentation agent for object size estimation",77,0.6370370370370371,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/persistence/MapJoinBytesTableContainer.java
"//  UNDONE: Add support for DATE, TIMESTAMP, INTERVAL_YEAR_MONTH, INTERVAL_DAY_TIME...","switch (primitiveCategory) {",225,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/vector/keyseries/VectorKeySeriesLongSerialized.java
"//  TODO: there was code here to create guess-estimate for collection wrt how usage changes   when removing elements. However it's too error-prone for anything involving   pre-allocated capacity, so it was discarded.","// We will estimate collection as an object (only if it's a field).",206,0.5914396887159533,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/storage-api/src/java/org/apache/hadoop/hive/ql/util/IncrementalObjectSizeEstimator.java
"//  Extract the buckedID from pathFilesMap, this is more accurate method,   however. it may not work in certain cases where buckets are named   after files used while loading data. In such case, fallback to old   potential inaccurate method.   The accepted file names are such as 000000_0, 000001_0_copy_1.","too long.",0,0,0
"//  This is a bit hackish to fix mismatch between SARG and Hive types   for Timestamp and Date. TODO: Move those types to storage-api.","if (o instanceof java.sql.Date) {",273,0.6748466257668712,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/FixedBucketPruningOptimizer.java
"//  TODO HIVE-14042. Move to using a loop and a timed wait once TEZ-3302 is fixed.","checkAbortCondition();",118,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/ReduceRecordProcessor.java
"//  TODO: add a configurable option to skip the history and just drop it?","return plan.getStatus() == Status.ACTIVE ? fullFromMResourcePlan(plan) : null;",11259,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/ObjectStore.java
"//  TODO: refactor this into an utility, LLAP tests use this pattern a lot","ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT);",315,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/service/src/test/org/apache/hive/service/cli/CLIServiceTest.java
"//  TODO: make aliases unique, otherwise needless rewriting takes place","Integer genColListRegex(String colRegex, String tabAlias, ASTNode sel,",3566,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"/*    * Derive additional attributes to be rendered by EXPLAIN.   * TODO: this method is relied upon by custom input formats to set jobconf properties.   *       This is madness? - This is Hive Storage Handlers!    */","public void deriveExplainAttributes() {",261,0.4558139534883721,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/MapWork.java
"/*    * Connects to the {@link IMetaStoreClient meta store} that will be used to manage {@link Transaction} life-cycles.   * Also checks that the tables destined to receive mutation events are able to do so. The client should only hold one   * open transaction at any given time (TODO: enforce this).    */","too long.",0,0,0
"//  TODO: this should have an option for directory to inherit from the parent table,         including bucketing and list bucketing, for the use in compaction when the         latter runs inside a transaction.","TableDesc ret = getDefaultTableDesc(Integer.toString(Utilities.ctrlaCode), cols,",113,0.6,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java
"//  UNDONE: Parameterize for implementation variation?","MapJoinDesc mapJoinDesc = MapJoinTestConfig.createMapJoinDesc(testDesc);",134,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hive-jmh/src/main/java/org/apache/hive/benchmark/vectorization/mapjoin/AbstractMapJoin.java
"//  TODO: ifExists could be moved to metastore. In fact it already supports that. Check it         for now since we get parts for output anyway, so we can get the error message         earlier... If we get rid of output, we can get rid of this.","if (parts.isEmpty()) {",4035,0.5758754863813229,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
"//  FIXME: moved default value to here...for now   i think this features is never really used from the command line","String defaultTestSrcTables = "src,src1,srcbucket,srcbucket2,src_json,src_thrift," +",231,0.6015037593984962,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  TODO : Should be moved out.","if (oldtbl",339,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hcatalog/webhcat/java-client/src/main/java/org/apache/hive/hcatalog/api/HCatClientHMSImpl.java
"//  TODO - types need to be checked.","List<FieldSchema> partCols = tTable.getPartitionKeys();",1762,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
"//  TODO: handle multi joins","return;",2131,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java
"//  TODO: ugly hack because Java doesn't have dtors and Tez input hangs on shutdown.","if (!isInitOk) {",389,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
"//  TODO: Make script output prefixing configurable. Had to disable this since   it results in lots of test diffs.","for (String cmd : cmds) {",2307,0.8301886792452831,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/beeline/src/java/org/apache/hive/beeline/BeeLine.java
"//  TODO: also support fileKey in splits, like OrcSplit does","if (metadataCache != null) {",194,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/vector/VectorizedParquetRecordReader.java
"//  TODO: when txn stats are implemented, use writeIds to determine stats accuracy","@SuppressWarnings("unused")",217,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/stats/StatsUpdaterThread.java
"//  Hive is pretty simple (read: stupid) in writing out values via the serializer.   We're just going to go through, matching indices.  Hive formats normally   handle mismatches with null.  We don't have that option, so instead we'll   end up throwing an exception for invalid records.","too long.",0,0,0
"//  TODO handle negations","throw new IllegalArgumentException("Negations not yet implemented");",109,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/predicate/AccumuloRangeGenerator.java
"//  TODO: handle task to container map events in case of hard failures","disabledNodesQueue.add(nodeInfo);",1584,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-tez/src/java/org/apache/hadoop/hive/llap/tezplugins/LlapTaskSchedulerService.java
"// TODO: partition names in getPartitionsByNames are not case insensitive","List<Partition> partitions = client.getPartitionsByNames(DB_NAME, TABLE_NAME,",336,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestGetPartitions.java
"//  todo this should be configured in serde","public static byte[] decodeIfNeeded(byte[] recv) {",55,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyBinary.java
"//  TODO: Have to put in the support for AS clause","Pattern regex = null;",3580,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
"//  Ideally we should use HiveRelNode convention. However, since Volcano planner   throws in that case because DruidQuery does not implement the interface,   we set it as Bindable. Currently, we do not use convention in Hive, hence that   should be fine.   TODO: If we want to make use of convention (e.g., while directly generating operator   tree instead of AST), this should be changed.","too long.",0,0,0
"// Call getSplit on the InputFormat, create an HCatSplit for each  underlying split. When the desired number of input splits is missing,  use a default number (denoted by zero).  TODO(malewicz): Currently each partition is split independently into  a desired number. However, we want the union of all partitions to be  split into a desired number while maintaining balanced sizes of input","too long.",0,0,0
"//  TODO: do we need to handle the "this is what MySQL does" here?","char nextChar = result.charAt(i + 1);",590,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java
"//  @deprecated in favour of {@link HCatTable.#bucketCols(List<FieldSchema>) and HCatTable.#numBuckets(int)}.   To be removed in Hive 0.16.","None",None,None,None
"//  TODO Watches on the output dirs need to be cancelled at some point. For now - via the expiry.","}",109,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/shufflehandler/DirWatcher.java
"/*          * TODO: Use the hard link feature of hdfs         * once https://issues.apache.org/jira/browse/HDFS-3370 is done          */","pathCreated = wh.renameDir(sourcePath, destPath, false);",4037,0.515625,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
"//  TODO: allow >1 port per host?","return LlapFixedRegistryImpl.this.port;",163,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-client/src/java/org/apache/hadoop/hive/llap/registry/impl/LlapFixedRegistryImpl.java
"//  NOTE: This is for generating the internal path name for partitions. Users   should always use the MetaStore API to get the path name for a partition.   Users should not directly take partition values and turn it into a path   name by themselves, because the logic below may change in the future.     In the future, it's OK to add new chars to the escape list, and old data   won't be corrupt, because the full path name in metastore is stored.   In that case, Hive will continue to read the old data, but when it creates   new partitions, it will use new names.   edit : There are some use cases for which adding new chars does not seem   to be backward compatible - Eg. if partition was created with name having   a special char that you want to start escaping, and then you try dropping   the partition with a hive version that now escapes the special char using   the list below, then the drop partition fails to work.","too long.",0,0,0
"//  TODO can we be more precise than string,string?","sb.append(serdeConstants.MAP_TYPE_NAME).append("<").append(serdeConstants.STRING_TYPE_NAME)",141,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/ColumnMapper.java
"//  TODO: this is wrong; this test sets up dummy txn manager and so it cannot create ACID tables.         If I change it to use proper txn manager, the setup for some tests hangs.         This used to work by accident, now this works due a test flag. The test needs to be fixed.   Create table","too long.",0,0,0
"//  TODO - currently no way to test alter partition, as HCatClient doesn't support it.","@Test",218,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/hcatalog-unit/src/test/java/org/apache/hive/hcatalog/api/TestHCatClientNotification.java
"//  Note - some of these scenarios could be handled, but they are not supported right now.   The reason is that we bind a query to app/user using the signed token information, and   we don't want to bother figuring out which one to use in case of ambiguity w/o a use case.   Ambiguous user.   Ambiguous user.   Ambiguous user.   Ambiguous app.","too long.",0,0,0
"//  only support bulkload when a hfile.family.path has been specified.   TODO: support detecting cf's from column mapping   TODO: support loading into multiple CF's at a time","String path = HiveHFileOutputFormat.getFamilyPath(jobConf, tableProperties);",269,0.5882352941176471,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/hbase-handler/src/java/org/apache/hadoop/hive/hbase/HBaseStorageHandler.java
"//  TODO Why is this changed from the default in hive-conf?","warehousePath = new Path(fsUriString, "/build/ql/test/data/warehouse/");",425,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/itests/util/src/main/java/org/apache/hadoop/hive/ql/QTestUtil.java
"//  TODO: need to set catalog parameter","if (types != null) {",729,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java
"//  TODO: Should have a check on the server side. Embedded metastore throws   NullPointerException, remote throws TTransportException","Assert.fail("Expected an NullPointerException or TTransportException to be thrown");",218,0.7045454545454546,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/standalone-metastore/src/test/java/org/apache/hadoop/hive/metastore/client/TestFunctions.java
"//  TODO: this will probably send a message to AM. Is that needed here?","taskWrapper.getTaskRunnerCallable().killTask();",632,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/TaskExecutorService.java
"//  There's full hash code stored in front of the key. We could check that first. If keyLength   is <= 4 it obviously doesn't make sense, less bytes to check in a key. Then, if there's a   match, we check it in vain. But what is the proportion of matches? For writes it could be 0   if all keys are unique, for reads we hope it's really high. Then if there's a mismatch what   probability is there that key mismatches in <4 bytes (so just checking the key is faster)?","too long.",0,0,0
"/*    * Given a RexCall & TableScan find max no of nulls. Currently it picks the   * col with max no of nulls.   *    * TODO: improve this   *    * @param call   * @param t   * @return    */","private BufferedRows getConfInternal(boolean call) {",785,0.15492957746478872,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/beeline/src/java/org/apache/hive/beeline/Commands.java
"//  NOTE: BeeLineOpts uses Reflector in an extensive way to call getters and setters on itself   If you want to add any getters or setters to this class, but not have it interfere with   saved variables in beeline.properties, careful use of this marker is needed.   Also possible to get this by naming these functions obtainBlah instead of getBlah   and so on, but that is not explicit and will likely surprise people looking at the   code in the future. Better to be explicit in intent.","too long.",0,0,0
"//  TODO: should this be currentDirs?","if (LOG.isInfoEnabled()) {",761,0.7654320987654321,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java
"//  TODO What else is required in this environment map.","env.putAll(localEnv);",235,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/llap-server/src/java/org/apache/hadoop/hive/llap/daemon/impl/ContainerRunnerImpl.java
"//  FIXME: HIVE-18703 should probably move this method somewhere else","public final boolean logicalEqualsTree(Operator<?> o) {",1605,1.0,/Users/yonekuramiki/Desktop/resarch/searchSATD-underCode/clone/ql/src/java/org/apache/hadoop/hive/ql/exec/Operator.java
